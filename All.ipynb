{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Athitiya00/efficientnet_keras_transfer_learning/blob/master/All.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "z8o_VVNXzcL8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_2Fe8u81d5r",
        "outputId": "e84af166-225a-4c27-c3cb-89d230e87b4c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv (r'/content/drive/My Drive/Human_age/All_Film.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "mbLFqTO1ze9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "6f167fd3-a1b7-4f6f-e30e-70e88aae419e"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Fig  Age(year) Class  Filename  \\\n",
              "0       1          7    Y7    V1.jpg   \n",
              "1       2          7    Y7    V2.jpg   \n",
              "2       3          7    Y7    V3.jpg   \n",
              "3       4          7    Y7    V6.jpg   \n",
              "4       5          7    Y7    V7.jpg   \n",
              "...   ...        ...   ...       ...   \n",
              "1836  143         18   Y18  S264.jpg   \n",
              "1837  144         18   Y18  S268.jpg   \n",
              "1838  145         18   Y18  S270.jpg   \n",
              "1839  146         18   Y18  S274.jpg   \n",
              "1840  147         18   Y18  S276.jpg   \n",
              "\n",
              "                                          Path_filename      Sex Floder  \n",
              "0     /content/drive/My Drive/Film pano/7 year/7Y-F/...  เพศหญิง   Both  \n",
              "1     /content/drive/My Drive/Film pano/7 year/7Y-F/...  เพศหญิง   Both  \n",
              "2     /content/drive/My Drive/Film pano/7 year/7Y-F/...  เพศหญิง   Both  \n",
              "3     /content/drive/My Drive/Film pano/7 year/7Y-F/...  เพศหญิง   Both  \n",
              "4     /content/drive/My Drive/Film pano/7 year/7Y-F/...  เพศหญิง   Both  \n",
              "...                                                 ...      ...    ...  \n",
              "1836  /content/drive/My Drive/Film pano/18 year/18Y ...   เพศชาย   Both  \n",
              "1837  /content/drive/My Drive/Film pano/18 year/18Y ...   เพศชาย   Both  \n",
              "1838  /content/drive/My Drive/Film pano/18 year/18Y ...   เพศชาย   Both  \n",
              "1839  /content/drive/My Drive/Film pano/18 year/18Y ...   เพศชาย   Both  \n",
              "1840  /content/drive/My Drive/Film pano/18 year/18Y ...   เพศชาย   Both  \n",
              "\n",
              "[1841 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-395afab0-1edc-4e17-a451-423cb896a469\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fig</th>\n",
              "      <th>Age(year)</th>\n",
              "      <th>Class</th>\n",
              "      <th>Filename</th>\n",
              "      <th>Path_filename</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Floder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Y7</td>\n",
              "      <td>V1.jpg</td>\n",
              "      <td>/content/drive/My Drive/Film pano/7 year/7Y-F/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Y7</td>\n",
              "      <td>V2.jpg</td>\n",
              "      <td>/content/drive/My Drive/Film pano/7 year/7Y-F/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>Y7</td>\n",
              "      <td>V3.jpg</td>\n",
              "      <td>/content/drive/My Drive/Film pano/7 year/7Y-F/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>Y7</td>\n",
              "      <td>V6.jpg</td>\n",
              "      <td>/content/drive/My Drive/Film pano/7 year/7Y-F/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>Y7</td>\n",
              "      <td>V7.jpg</td>\n",
              "      <td>/content/drive/My Drive/Film pano/7 year/7Y-F/...</td>\n",
              "      <td>เพศหญิง</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1836</th>\n",
              "      <td>143</td>\n",
              "      <td>18</td>\n",
              "      <td>Y18</td>\n",
              "      <td>S264.jpg</td>\n",
              "      <td>/content/drive/My Drive/Film pano/18 year/18Y ...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1837</th>\n",
              "      <td>144</td>\n",
              "      <td>18</td>\n",
              "      <td>Y18</td>\n",
              "      <td>S268.jpg</td>\n",
              "      <td>/content/drive/My Drive/Film pano/18 year/18Y ...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1838</th>\n",
              "      <td>145</td>\n",
              "      <td>18</td>\n",
              "      <td>Y18</td>\n",
              "      <td>S270.jpg</td>\n",
              "      <td>/content/drive/My Drive/Film pano/18 year/18Y ...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1839</th>\n",
              "      <td>146</td>\n",
              "      <td>18</td>\n",
              "      <td>Y18</td>\n",
              "      <td>S274.jpg</td>\n",
              "      <td>/content/drive/My Drive/Film pano/18 year/18Y ...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1840</th>\n",
              "      <td>147</td>\n",
              "      <td>18</td>\n",
              "      <td>Y18</td>\n",
              "      <td>S276.jpg</td>\n",
              "      <td>/content/drive/My Drive/Film pano/18 year/18Y ...</td>\n",
              "      <td>เพศชาย</td>\n",
              "      <td>Both</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1841 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-395afab0-1edc-4e17-a451-423cb896a469')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-395afab0-1edc-4e17-a451-423cb896a469 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-395afab0-1edc-4e17-a451-423cb896a469');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['Y7','Y8','Y9','Y10','Y11','Y12','Y13','Y16','Y17','Y18']\n",
        "len(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRBrW9is1vcq",
        "outputId": "90c04ee0-2164-46f0-ed5b-db7522e06a34"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34H1ad-Q2gAN",
        "outputId": "535a2021-390f-404a-d99c-e5bd44ba7833"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1841, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(set(df['Class'])))\n",
        "print(set(df['Class']))\n",
        "df.shape"
      ],
      "metadata": {
        "id": "A2iRu-NoHd37",
        "outputId": "d5d0aec6-84a5-4bed-e701-f3e01859cfd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "{'Y13', 'Y12', 'Y17', 'Y8', 'Y7', 'Y18', 'Y16', 'Y9', 'Y10', 'Y11'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1841, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clone efficientnet repo\n"
      ],
      "metadata": {
        "id": "pumGmy6f3eSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ดึงข้อมูลใน Github มาใช้\n",
        "import os\n",
        "%cd /content\n",
        "if not os.path.isdir(\"efficientnet_keras_transfer_learning\"):\n",
        "  !git clone https://github.com/Wanita-8943/efficientnet_keras_transfer_learning\n",
        "%cd efficientnet_keras_transfer_learning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7iy2f8n16p0",
        "outputId": "a3936d4d-78a7-4d43-be3b-37e592537413"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/efficientnet_keras_transfer_learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_dir = '/content/drive/My Drive/HA'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Directories for our training,\n",
        "# validation and test splits\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(test_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "nqCFbjRQ3okB"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classes = ['Y7','Y8','Y9','Y10','Y11','Y12','Y13','Y16','Y17','Y18']\n",
        "#len(classes) \n",
        "#{'Y13', 'Y12', 'Y17', 'Y8', 'Y7', 'Y18', 'Y16', 'Y9', 'Y10', 'Y11'}\n",
        "#(1841, 5)"
      ],
      "metadata": {
        "id": "YNkJycxmK0nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory with our training cat pictures\n",
        "validation_Y7_dir = os.path.join(validation_dir, 'Y7')\n",
        "os.makedirs(validation_Y7_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "validation_Y8_dir = os.path.join(validation_dir, 'Y8')\n",
        "os.makedirs(validation_Y8_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "validation_Y9_dir = os.path.join(validation_dir, 'Y9')\n",
        "os.makedirs(validation_Y9_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "validation_Y10_dir = os.path.join(validation_dir, 'Y10')\n",
        "os.makedirs(validation_Y10_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "validation_Y11_dir = os.path.join(validation_dir, 'Y11')\n",
        "os.makedirs(validation_Y11_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "validation_Y12_dir = os.path.join(validation_dir, 'Y12')\n",
        "os.makedirs(validation_Y12_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "validation_Y13_dir = os.path.join(validation_dir, 'Y13')\n",
        "os.makedirs(validation_Y13_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "validation_Y16_dir = os.path.join(validation_dir, 'Y16')\n",
        "os.makedirs(validation_Y16_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "validation_Y17_dir = os.path.join(validation_dir, 'Y17')\n",
        "os.makedirs(validation_Y17_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "validation_Y18_dir = os.path.join(validation_dir, 'Y18')\n",
        "os.makedirs(validation_Y18_dir, exist_ok=True)\n",
        "\n",
        "# Directory with our training cat pictures\n",
        "train_Y7_dir = os.path.join(train_dir, 'Y7')\n",
        "os.makedirs(train_Y7_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "train_Y8_dir = os.path.join(train_dir, 'Y8')\n",
        "os.makedirs(train_Y8_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "train_Y9_dir = os.path.join(train_dir, 'Y9')\n",
        "os.makedirs(train_Y9_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "train_Y10_dir = os.path.join(train_dir, 'Y10')\n",
        "os.makedirs(train_Y10_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "train_Y11_dir = os.path.join(train_dir, 'Y11')\n",
        "os.makedirs(train_Y11_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "train_Y12_dir = os.path.join(train_dir, 'Y12')\n",
        "os.makedirs(train_Y12_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "train_Y13_dir = os.path.join(train_dir, 'Y13')\n",
        "os.makedirs(train_Y13_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "train_Y16_dir = os.path.join(train_dir, 'Y16')\n",
        "os.makedirs(train_Y16_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "train_Y17_dir = os.path.join(train_dir, 'Y17')\n",
        "os.makedirs(train_Y17_dir, exist_ok=True)\n",
        "# Directory with our training cat pictures\n",
        "train_Y18_dir = os.path.join(train_dir, 'Y18')\n",
        "os.makedirs(train_Y18_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "oLVNWv5g4Xwv"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Copy views images to rain_views_dir"
      ],
      "metadata": {
        "id": "iFPiVyX6NKJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Path images\n",
        "val = df[df['Fig'].between(1, 10)]\n",
        "train = df[df['Fig'].between(11, 200)]\n",
        "\n",
        "#Path images of validation\n",
        "y7_val = val[val['Class']=='Y7' ]\n",
        "y7_path_val = y7_val['Path_filename'].tolist() \n",
        "y8_val = val[val['Class']=='Y8' ]\n",
        "y8_path_val = y8_val['Path_filename'].tolist()\n",
        "y9_val = val[val['Class']=='Y9' ]\n",
        "y9_path_val = y9_val['Path_filename'].tolist()\n",
        "y10_val = val[val['Class']=='Y10' ]\n",
        "y10_path_val = y10_val['Path_filename'].tolist()\n",
        "y11_val = val[val['Class']=='Y11' ]\n",
        "y11_path_val = y11_val['Path_filename'].tolist()\n",
        "y12_val = val[val['Class']=='Y12' ]\n",
        "y12_path_val = y12_val['Path_filename'].tolist()\n",
        "y13_val = val[val['Class']=='Y13' ]\n",
        "y13_path_val = y13_val['Path_filename'].tolist()\n",
        "y16_val = val[val['Class']=='Y16' ]\n",
        "y16_path_val = y16_val['Path_filename'].tolist()\n",
        "y17_val = val[val['Class']=='Y17' ]\n",
        "y17_path_val = y17_val['Path_filename'].tolist()\n",
        "y18_val = val[val['Class']=='Y18' ]\n",
        "y18_path_val = y18_val['Path_filename'].tolist()\n",
        "\n",
        "#Path images of train\n",
        "y7_train = train[train['Class']=='Y7' ]\n",
        "y7_path_train = y7_train['Path_filename'].tolist() \n",
        "y8_train = train[train['Class']=='Y8' ]\n",
        "y8_path_train = y8_train['Path_filename'].tolist() \n",
        "y9_train = train[train['Class']=='Y9' ]\n",
        "y9_path_train = y9_train['Path_filename'].tolist()\n",
        "y10_train = train[train['Class']=='Y10' ]\n",
        "y10_path_train = y10_train['Path_filename'].tolist()\n",
        "y11_train = train[train['Class']=='Y11' ]\n",
        "y11_path_train = y11_train['Path_filename'].tolist()\n",
        "y12_train = train[train['Class']=='Y12' ]\n",
        "y12_path_train = y12_train['Path_filename'].tolist()\n",
        "y13_train = train[train['Class']=='Y13' ]\n",
        "y13_path_train = y13_train['Path_filename'].tolist()\n",
        "y16_train = train[train['Class']=='Y16' ]\n",
        "y16_path_train = y16_train['Path_filename'].tolist()      \n",
        "y17_train = train[train['Class']=='Y17' ]\n",
        "y17_path_train = y17_train['Path_filename'].tolist() \n",
        "y18_train = train[train['Class']=='Y18' ]\n",
        "y18_path_train = y18_train['Path_filename'].tolist() "
      ],
      "metadata": {
        "id": "4kYP3VrdNFw7"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# copy images each view to validation_view_dir\n",
        "fnames = y7_path_val  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y7_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = y8_path_val  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y8_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "fnames = y9_path_val  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y9_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = y10_path_val  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y10_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "fnames = y11_path_val  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y11_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)  \n",
        "\n",
        "fnames = y12_path_val  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y12_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)  \n",
        "    \n",
        "fnames = y13_path_val  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y13_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "fnames = y16_path_val  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y16_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "fnames = y17_path_val  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y17_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "fnames = y18_path_val  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(validation_Y18_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "# copy images each view to train_view_dir\n",
        "\n",
        "    fnames = y7_path_train  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y7_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "fnames = y8_path_train  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y8_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "fnames = y9_path_train  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y9_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = y10_path_train  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y10_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "fnames = y11_path_train  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y11_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = y12_path_train  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y12_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = y13_path_train  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y13_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "\n",
        "fnames = y16_path_train  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y16_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "fnames = y17_path_train  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y17_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    \n",
        "fnames = y18_path_train  \n",
        "for fname in fnames:\n",
        "    dst = os.path.join(train_Y18_dir, os.path.basename(fname))\n",
        "    shutil.copyfile(fname, dst)\n",
        "    "
      ],
      "metadata": {
        "id": "0CwRAq70f2WY"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show number of train&val\n",
        "\n",
        "print('total training images:', len(os.listdir(train_Y7_dir))+len(os.listdir(train_Y8_dir))+len(os.listdir(train_Y9_dir))+len(os.listdir(train_Y10_dir))\n",
        "      +len(os.listdir(train_Y11_dir))+len(os.listdir(train_Y12_dir))+len(os.listdir(train_Y13_dir))+len(os.listdir(train_Y16_dir))+len(os.listdir(train_Y17_dir)))\n",
        "print('total training Y7 images:', len(os.listdir(train_Y7_dir)))\n",
        "print('total training Y8 images:', len(os.listdir(train_Y8_dir)))\n",
        "print('total training Y9 images:', len(os.listdir(train_Y9_dir)))\n",
        "print('total training Y10 images:', len(os.listdir(train_Y10_dir)))\n",
        "print('total training Y11 images:', len(os.listdir(train_Y11_dir)))\n",
        "print('total training Y12 images:', len(os.listdir(train_Y12_dir)))\n",
        "print('total training Y13 images:', len(os.listdir(train_Y13_dir)))\n",
        "print('total training Y16 images:', len(os.listdir(train_Y16_dir)))\n",
        "print('total training Y17 images:', len(os.listdir(train_Y17_dir)))\n",
        "print('total training Y18 images:', len(os.listdir(train_Y18_dir)),'\\n')\n",
        "\n",
        "print('total validation images:', len(os.listdir(validation_Y7_dir))+len(os.listdir(validation_Y8_dir))+len(os.listdir(validation_Y9_dir))\n",
        "      +len(os.listdir(validation_Y10_dir))+len(os.listdir(validation_Y11_dir))+len(os.listdir(validation_Y12_dir))+len(os.listdir(validation_Y13_dir))\n",
        "      +len(os.listdir(validation_Y16_dir))+len(os.listdir(validation_Y17_dir))+len(os.listdir(validation_Y18_dir)))\n",
        "print('total validation Y7 images:', len(os.listdir(validation_Y7_dir)))\n",
        "print('total validation Y8 images:', len(os.listdir(validation_Y8_dir)))\n",
        "print('total validation Y9 images:', len(os.listdir(validation_Y9_dir)))\n",
        "print('total validation Y10 images:', len(os.listdir(validation_Y10_dir)))\n",
        "print('total validation Y11 images:', len(os.listdir(validation_Y11_dir)))\n",
        "print('total validation Y12 images:', len(os.listdir(validation_Y12_dir)))\n",
        "print('total validation Y13 images:', len(os.listdir(validation_Y13_dir)))\n",
        "print('total validation Y16 images:', len(os.listdir(validation_Y16_dir)))\n",
        "print('total validation Y17 images:', len(os.listdir(validation_Y17_dir)))\n",
        "print('total validation Y18 images:', len(os.listdir(validation_Y18_dir)))\n"
      ],
      "metadata": {
        "id": "z-XUK2pvlpXe",
        "outputId": "479dc8be-5a95-45c6-a828-217a2b768a7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total training images: 1634\n",
            "total training Y7 images: 190\n",
            "total training Y8 images: 200\n",
            "total training Y9 images: 200\n",
            "total training Y10 images: 200\n",
            "total training Y11 images: 178\n",
            "total training Y12 images: 186\n",
            "total training Y13 images: 153\n",
            "total training Y16 images: 171\n",
            "total training Y17 images: 156\n",
            "total training Y18 images: 137 \n",
            "\n",
            "total validation images: 100\n",
            "total validation Y7 images: 10\n",
            "total validation Y8 images: 10\n",
            "total validation Y9 images: 10\n",
            "total validation Y10 images: 10\n",
            "total validation Y11 images: 10\n",
            "total validation Y12 images: 10\n",
            "total validation Y13 images: 10\n",
            "total validation Y16 images: 10\n",
            "total validation Y17 images: 10\n",
            "total validation Y18 images: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trainning EfficientNet"
      ],
      "metadata": {
        "id": "6sM-7zOh4Aao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import sys\n",
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image\n",
        "from tensorflow.keras import callbacks\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "2zGv_zKk0mQp"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyper parameters"
      ],
      "metadata": {
        "id": "C71fDSUN4TKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#only have 2 label\n",
        "batch_size = 50 #จำนวน data ที่ส่งไป Train ในแต่ละครั้ง จนครบจำนวนเต็ม x_train\n",
        "\n",
        "width = 150 \n",
        "height = 150 \n",
        "input_shape = (height, width, 3) #ขนาด image enter\n",
        "\n",
        "epochs = 20  #จำนวนรอบในการ Train\n",
        "NUM_TRAIN = 1634# จำนวนภาพ Train\n",
        "NUM_TEST = 100 #จำนวนภาพ Test\n",
        "dropout_rate = 0.2 #คือการปิดบาง Node หรือเรียกว่าทำการ Drop Out ไป ซึ่งขึ้นกับการตั้งค่าว่าจะให้ลืมไปกี่เปอร์เซนต์ดี ช่วยในการแก้ปัญหา Overfitting"
      ],
      "metadata": {
        "id": "JoZMdeMx4Ddh"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import efficientnet and load the conv base model"
      ],
      "metadata": {
        "id": "cUVkTI_p_JCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3\n",
        "# Higher the number, the more complex the model is.\n",
        "\n",
        "from efficientnet import EfficientNetB0 as Net\n",
        "from efficientnet import center_crop_and_resize, preprocess_input"
      ],
      "metadata": {
        "id": "pDzDxejw_KfG"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading pretrained conv base model\n",
        "\n",
        "conv_base = Net(weights='imagenet', include_top=False, input_shape=input_shape) # ไม่โหลด weights ของ layer สุดท้าย  include_top=False "
      ],
      "metadata": {
        "id": "_bBzzxch_1ST"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Setting data augmentation"
      ],
      "metadata": {
        "id": "FojrqDTuAI29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data augmentation เพื่อลดโอกาสการเกิด overfitting\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255, # image input 0-255 --> 0-1 เปลี่ยนค่าสี\n",
        "      rotation_range=40, # หมุนภาพในองศา\n",
        "      width_shift_range=0.2, #เปลี่ยนความกว้าง\n",
        "      height_shift_range=0.2, #ปลี่ยนความสูง\n",
        "      shear_range=0.2, #ทำให้ภาพเบี้ยว\n",
        "      zoom_range=0.2, #ซุม image มากสุด 20%\n",
        "      horizontal_flip=True, #พลิกภาพแบบสุ่มตามแนวนอน\n",
        "      fill_mode='nearest') \n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # This is the target directory\n",
        "        train_dir,\n",
        "        # All images will be resized to target height and width.\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        color_mode= 'rgb',\n",
        "        # Since we use categorical_crossentropy loss, we need categorical labels\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(height, width),\n",
        "        batch_size=batch_size,\n",
        "        color_mode= 'rgb',\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "8Kmq3hwnADqg",
        "outputId": "7f42e67d-31ca-4d7b-b90d-5e4017760685",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1771 images belonging to 10 classes.\n",
            "Found 100 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ตรง Found ของ train ได้ไม่ตรงกับข้างบน"
      ],
      "metadata": {
        "id": "crOpkGK4Jerk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show architecture model"
      ],
      "metadata": {
        "id": "y4x7o67vJbPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "# model.add(layers.Flatten(name=\"flatten\"))\n",
        "if dropout_rate > 0:\n",
        "    model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "# model.add(layers.Dense(256, activation='relu', name=\"fc1\"))\n",
        "model.add(layers.Dense(10, activation='softmax', name=\"fc_out\"))        #class --> 10 **Sub"
      ],
      "metadata": {
        "id": "FIRD1PVOAR2O"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "-xqKzPDjJ-rF",
        "outputId": "513c330e-503b-4d8c-8b20-47736a2f3c45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnet-b0 (Functional  (None, 5, 5, 1280)       4049564   \n",
            " )                                                               \n",
            "                                                                 \n",
            " gap (GlobalMaxPooling2D)    (None, 1280)              0         \n",
            "                                                                 \n",
            " dropout_out (Dropout)       (None, 1280)              0         \n",
            "                                                                 \n",
            " fc_out (Dense)              (None, 10)                12810     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,062,374\n",
            "Trainable params: 4,020,358\n",
            "Non-trainable params: 42,016\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('This is the number of trainable layers '\n",
        "      'before freezing the conv base:', len(model.trainable_weights))\n",
        "\n",
        "conv_base.trainable = False  # freeze เพื่อรักษา convolutional base's weight\n",
        "\n",
        "print('This is the number of trainable layers '\n",
        "      'after freezing the conv base:', len(model.trainable_weights))  #freez แล้วจะเหลือ max pool and dense"
      ],
      "metadata": {
        "id": "jvQ0rubMJ_n5",
        "outputId": "0c72b0d3-206c-420b-a567-cb279c611485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable layers before freezing the conv base: 213\n",
            "This is the number of trainable layers after freezing the conv base: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "xoBfzWZwK8nW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
        "              metrics=['acc'])\n",
        "\n",
        "#history คือตัวแปรที่จะทำการเก็บประวัติการ Train Model ของเรา\n",
        "#คำสั่ง Train\n",
        "history = model.fit_generator(\n",
        "      train_generator,#โหลดdataเข้ามา\n",
        "      steps_per_epoch= NUM_TRAIN //batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data=validation_generator, #validation_data=(x_valid, y_valid): ใส่ data ที่เราแยกไว้เพื่อดูผล Model ว่าเกิด Overfitting เริ่มที่จุดใด\n",
        "      validation_steps= NUM_TEST //batch_size,\n",
        "      verbose=1, #โชว์ผลลัพธ์ 0:ปิด\n",
        "      use_multiprocessing=True, #ใช้ GPU หลายตัว\n",
        "      workers=1) #ทำพร้อมกันที่ละ 4 ตัว"
      ],
      "metadata": {
        "id": "YD2OKq1xKRU7",
        "outputId": "51df866f-e09c-485d-aacf-3c3c8cba4f6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "32/32 [==============================] - 93s 3s/step - loss: 4.0511 - acc: 0.1050 - val_loss: 3.1918 - val_acc: 0.1200\n",
            "Epoch 2/20\n",
            "32/32 [==============================] - 81s 2s/step - loss: 3.6989 - acc: 0.1165 - val_loss: 2.9559 - val_acc: 0.0900\n",
            "Epoch 3/20\n",
            "32/32 [==============================] - 82s 3s/step - loss: 3.5010 - acc: 0.1292 - val_loss: 2.8771 - val_acc: 0.1300\n",
            "Epoch 4/20\n",
            "32/32 [==============================] - 86s 3s/step - loss: 3.3771 - acc: 0.1082 - val_loss: 2.8280 - val_acc: 0.1600\n",
            "Epoch 5/20\n",
            "32/32 [==============================] - 85s 3s/step - loss: 3.2949 - acc: 0.1190 - val_loss: 2.8288 - val_acc: 0.1600\n",
            "Epoch 6/20\n",
            "32/32 [==============================] - 82s 3s/step - loss: 3.2856 - acc: 0.1273 - val_loss: 2.8298 - val_acc: 0.1800\n",
            "Epoch 7/20\n",
            "32/32 [==============================] - 83s 2s/step - loss: 3.3472 - acc: 0.1120 - val_loss: 2.7980 - val_acc: 0.1900\n",
            "Epoch 8/20\n",
            "32/32 [==============================] - 89s 3s/step - loss: 3.1097 - acc: 0.1343 - val_loss: 2.7857 - val_acc: 0.1800\n",
            "Epoch 9/20\n",
            "32/32 [==============================] - 88s 3s/step - loss: 3.1455 - acc: 0.1394 - val_loss: 2.7911 - val_acc: 0.1800\n",
            "Epoch 10/20\n",
            "32/32 [==============================] - 87s 3s/step - loss: 3.1565 - acc: 0.1445 - val_loss: 2.7605 - val_acc: 0.2100\n",
            "Epoch 11/20\n",
            "32/32 [==============================] - 89s 3s/step - loss: 2.9702 - acc: 0.1540 - val_loss: 2.7163 - val_acc: 0.1900\n",
            "Epoch 12/20\n",
            "32/32 [==============================] - 82s 3s/step - loss: 3.0527 - acc: 0.1585 - val_loss: 2.7004 - val_acc: 0.2100\n",
            "Epoch 13/20\n",
            "32/32 [==============================] - 81s 2s/step - loss: 2.9947 - acc: 0.1630 - val_loss: 2.6865 - val_acc: 0.2300\n",
            "Epoch 14/20\n",
            "32/32 [==============================] - 91s 3s/step - loss: 3.0054 - acc: 0.1688 - val_loss: 2.6770 - val_acc: 0.2300\n",
            "Epoch 15/20\n",
            "32/32 [==============================] - 81s 2s/step - loss: 3.0239 - acc: 0.1534 - val_loss: 2.6575 - val_acc: 0.2300\n",
            "Epoch 16/20\n",
            "32/32 [==============================] - 87s 3s/step - loss: 3.0118 - acc: 0.1579 - val_loss: 2.6309 - val_acc: 0.2300\n",
            "Epoch 17/20\n",
            "32/32 [==============================] - 87s 3s/step - loss: 2.9236 - acc: 0.1612 - val_loss: 2.6239 - val_acc: 0.2200\n",
            "Epoch 18/20\n",
            "32/32 [==============================] - 84s 3s/step - loss: 2.9363 - acc: 0.1591 - val_loss: 2.5794 - val_acc: 0.2300\n",
            "Epoch 19/20\n",
            "32/32 [==============================] - 85s 3s/step - loss: 2.9757 - acc: 0.1579 - val_loss: 2.5732 - val_acc: 0.2300\n",
            "Epoch 20/20\n",
            "32/32 [==============================] - 83s 3s/step - loss: 2.9390 - acc: 0.1598 - val_loss: 2.5683 - val_acc: 0.2200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-9aOvx0uLCgw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}